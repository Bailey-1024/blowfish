
[{"content":" 启动 # 启动 ZooKeeper（三台机器都需要执行，使用自己写的脚本） [root@node01 ~]# zookeeper start 或者zookeeper内置命令 zkServer.sh start zkServer.sh status 启动 HDFS + YARN。 [root@node01 ~]# start-all.sh 启动HBase start-hbase.sh 访问 # Web 访问：http://node01:16010 结果如下。\nWeb 访问：http://node02:16010 结果如下。\n关闭 # 关闭HBase [root@node01 ~]# stop-hbase.sh 关闭HDFS [root@node01 ~]# stop-all.sh 关闭Zookeeper [root@node01 ~]# zookeeper stop 或者zookeeper内置命令 zkServer.sh stop ","date":"2024-07-27","externalUrl":null,"permalink":"/docs/hbase-start/","section":"Docs","summary":"启动 # 启动 ZooKeeper（三台机器都需要执行，使用自己写的脚本） [root@node01 ~]# zookeeper start 或者zookeeper内置命令 zkServer.","title":"hbase启动步骤","type":"docs"},{"content":" 问题一：主从模式和主备模式的区别？ # 个人理解：\n主从模式和主备模式的区在于从节点和备用节点。\n从节点在主节点正常运行时，从节点会提供读服务。\n备用节点在主节点正常运行时，备用节点不会提供读服务。\nAI回答：\n","date":"2024-07-27","externalUrl":null,"permalink":"/docs/problems/","section":"Docs","summary":"问题一：主从模式和主备模式的区别？ # 个人理解：","title":"学习大数据时遇到的问题","type":"docs"},{"content":" HBase # 基本概念 # 什么是HBase # ​\tHBase是一个开源的、高可靠性、高性能、面向列（这里指列族，非列式存储）、可伸缩、实时读写的分布式数据库。\nHBase有什么用 # ​\tHBase拥有良好的分布式架构设计可以让海量数据进行快速存储，提供高效、可扩展的分布式存储解决方案，用于处理大规模的结构化或非结构化数据。\n特点 # 拓展 # HBse与RDBMS(关系数据库管理系统)的区别：\n数据模型 # ​\t在HBase表中一行数据一下几个属性：一个主键（RowKey），列族（Column Family）下的多个列（Column Qualifier），并且含有一个或多个以时间戳（TimeStamp）来实现的版本号（Version）。\n​\t数据模型图：\n​\t核心元素：\nNameSpace（命名空间） 命名空间类似于关系型数据库中的数据库的概念，他其实是表的逻辑分组。这种抽象为多租户相关功能奠定了基础。命名空间是可以管理维护的，可以创建，删除或更改命名空间。HBase 有两个特殊预定义的命名空间：\ndefault：没有明确指定命名空间的表将自动落入此命名空间\nhbase：系统命名空间，用于包含 HBase 的内部表和元数据表\nTable（表） Table 和关系型数据库中的表一个意思，由行和列组成。\nRowKey(主键)\nRowKey 的概念与关系型数据库中的主键相似，是一行数据的唯一标识。RowKey 可以是任意字符串（最大长度是=64KB，实际应用中长度一般为 10-100 Bytes），RowKey 以字节数组保存。存储数据时，数据会按照 RowKey 的字典序排序存储，所以设计 RowKey 时，要充分利用排序存储这个特性，将经常一起读取的行存放到一起。\n访问 HBase 数据的方式有三种：\n基于 RowKey 的单行查询； 基于 RowKey 的范围查询； 全表扫描查询。 Column Family（列族）\nColumn Family 即列族，HBase 基于列划分数据的物理存储，同一个列族中列的数据在物理上都存储在同一个 HFile中。一个列族可以包含任意多列，一般同一类的列会放在一个列族中，每个列族都有一组存储属性：|\n是否应该缓存在内存中； 数据如何被压缩或行键如何编码等。 Column Qualifier(列) 列族的限定词，理解为列的唯一标识。但是列标识是可以改变的，因此每一行可能有不同的列标识。使用的时候必须 (列族:列) ，列可以根据需求动态添加或者删除，同一个表中不同行的数据列都可以不同。\nTimestamp（时间戳） Timestamp是实现Hbase多个版本的关键。相同 RowKey 的数据按照 Timestamp 倒序排列，默认查询的是最新的版本，当然用户也可以指定 Timestamp 的值来读取指定版本的数据。 为了避免数据存在过多版本而造成管理（包括存贮和索引）负担，HBase 提供了两种数据版本回收方案： 一是保存数据的最后 n 个版本 二是保存最近一段时间内的版本（比如最近七天）\nCell（单元格） Cell 由 Row，Column Family，Column Qualifier，Version 组成。\n架构模型 # 总体架构 # ​\tHBase建立在Hadoop之上，利用Hadoop HDFS作为其底层存储系统，并借助Hadoop MapReduce提供高性能的数据处理能力。同时，HBase利用Zookeeper进行集群状态的监控、元数据的管理以及集群配置的维护。\n核心组件 # Zookeeper HBase 通过 ZooKeeper 来完成选举 HMaster、监控 HRegionServer、维护元数据集群配置等工作。主要工作职责如下：\n选举 HMaster：保证任何时候，集群中只有一个 HMaster。实现 HMaster 主从节点的 故障转移（Failover）； 监控 HRegionServer（节点探活）：实时监控 HRegionServer 的状态，将 HRegionServer 的上下线信息实时报告给Hmaster 维护元数据和集群配置：存放整个 HBase 集群的元数据以及集群的状态信息，包括： 存储所有 HRegion 的寻址入口（hbase:meta 元数据表），存储所有的的元数据信息； 存储 HBase 的 架构（Schema），包括有哪些 Table，每个 Table 有哪些 Column Family。 Client HBase Client 为用户提供了访问 HBase 的接口，可以通过元数据表（客户端负责发送请求到数据库）来定位到目标数据的 HRegionServer。客户端连接的方式有很多种： HBase shell和Java API。\n​\t发送的请求主要包括：\nDDL：数据库定义语言（表的建立，删除，添加删除列族，控制版本） DML：数据库操作语言（增删改） DQL：数据库查询语言（查询，全表扫描，基于主键，基于过滤器） HMaster HMaster 是 HBase 集群的主节点，负责整个集群的管理工作，HMaster 可以实现高可用（Active 和 Backup），通过 ZooKeeper 来维护主备节点的切换。\n**管理分配：**管理和分配 HRegion，负责启动的时候分配 HRegion 到具体的 HRegionServer，又或者在分割 HRegion 时关于新 HRegion 的分配。管理用户对 Table 结构的 DDL（创建，删除，修改）操作。 **负载均衡：**一方面负责将用户的数据均衡地分布在各个 HRegionServer 上，防止 HRegionServer 数据倾斜过载。另一方面负责将用户的请求均衡地分布在各个 HRegionServer 上，防止 HRegionServer 请求过热； **维护数据：**发现失效的 HRegion，并将失效的 HRegion 分配到正常的 HRegionServer 上。当某个 HRegionServer 下线时迁移其内部的 HRegion 到其他 HRegionServer 上。 权限控制。 HRegionServer\n​\tHRegionServer 直接对接用户的读写请求，是真正干活的节点，属于 HBase 具体数据的管理者。主要工作职责如下：\n实时和 HMaster 保持心跳，汇报当前节点的信息； 当接收到 HMaster 的命令创建表时，会分配一个 HRegion 对应一张表； 负责切分在运行过程中变得过大的 HRegion； 当 HRegionServer 意外关闭的时候，当前节点的 HRegion 会被其他 HRegionServer 管理； 维护 HMaster 分配给它的 HRegion，处理对这些 HRegion 的 IO 请求； 当客户端发送 DML 和 DQL 操作时，HRegionServer 负责和客户端建立连接； WAL：Write Ahead Log 日志先行。记录了数据写入、更新日志，它被用来做故障恢复； MemStore：写缓存，数据首先会被写入到 MemStore 中。每个 HRegion 的每个 Column Family 都会有一个MemStore 负责与底层的 HDFS 交互，存储数据（HLog、HFile）到 HDFS。 BlockCache：读缓存，在内存中存储了最常访问的数据，采用 LRU 机制进行淘汰。 HRegion\n​\t一个 HRegionServer 包含了多个 HRegion。HBase 将表中的数据基于 RowKey 的不同范围划分到不同 HRegion 上，每个 HRegion 都负责一定范围的数据存储和访问。\n​\tHRegion 是 HBase 中分布式存储和负载均衡的最小单元，不同的 HRegion 可以分布在不同的 HRegionServer 上。每个表一开始只有一个 HRegion，随着数据不断插入表，HRegion 不断增大，当增大到指定阀值（10G）的时候，HRegion 就会等分成两个HRegion，切分后其中一个 HRegion 会被转移到其他的 HRegionServer 上，实现负载均衡。\nStore\n​\t一个 HRegion 由多个 Store 组成，每个 Store 都对应一个 Column Family，Store 包含 1 个 MemStore 和 0 或多个StoreFile 组成。\nMemStore：作为 HBase 的内存数据存储，数据的写操作会先写到 MemStore 中，当 MemStore 中的数据增长到指定阈值（默认 128M）后，HRegionServer 会启动 FlushCache 进程将 MemStore 中的数据写入 StoreFile 持久化存储，每次写入后都形成一个单独的 StoreFile。当客户端检索数据时，先在 MemStore 中查找，如果 MemStore 中不存在，则会在StoreFile 中继续查找。 **StoreFile：**MemStore 中的数据写到文件后就是 StoreFile，StoreFile 底层是以 HFile 格式保存的。HBase 以 StoreFile 的大小来判断是否需要切分 HRegion。当一个 HRegion 中所有 StoreFile 的大小和数量都增长到超过指定阈值时，HMaster会把当前 HRegion 分割为两个，切分后其中一个 HRegion 会被转移到其他的 HRegionServer 上，实现负载均衡。 **HFile：**HFile 和 StoreFile 是同一个文件，只不过站在 HDFS 的角度称这个文件为 HFile，站在 HBase 的角度就称这个文 件为 StoreFile。是 HBase 在 HDFS 中存储数据的格式，它包含多层的索引，这样在 HBase 检索数据的时候就不用完全 的加载整个文件。 HFile\nHLog\n​\t一个 HRegionServer 只有一个 HLog 文件。负责记录数据的操作日志，当 HBase 出现故障时可以进行日志重放、故障恢复。例如磁盘掉电导致 MemStore 中的数据没有持久化存储到 StoreFile，这时就可以通过 HLog 日志重放来恢复数据。\n​\tHLog 文件就是一个普通的 Hadoop Sequence File，Sequece File 的 Key 是 HLogKey 对象，Sequece File 的 Value 是HBase 的 KeyValue 对象，即本次的操作。\n​\tHLogKey 中记录了写入数据的归属信息，除了 Table 和 HRegion 名称外，同时还包括 Sequence Number 和Timestamp：\nTimestamp：写入时间。\nSequence Number：起始值为 0，或者是最近一次存入文件系统中的 Sequence Number。\n数据被写入 WAL 后，会被加入到 MemStore 即写缓存。然后服务端就可以向客户端返回 ack 表示写数据完成。\nHDFS\n​\tHDFS 为 HBase 提供底层数据存储服务，同时为 HBase 提供高可用支持。HBase 将 HLog 存储在 HDFS 上，当服务器发生异常宕机时，可以重放 HLog 来恢复数据。\nBlockCache # 读写流程 # ​\tHBase 中单表的数据量通常可以达到 TB 级或 PB 级，但大多数情况下数据读取可以做到毫秒级。\n三层索引 # HBase0.96以前 # ​\tHBase 0.96 以前内部维护了两张特殊的表： -ROOT- 表和 .META. 表，用来查找各种表的 HRegion 位置。这两张特殊的表也像 HBase 中的其他表一样会切分成多个 HRegion。 -ROOT- 表比 .META. 更特殊一些，只能包含一个完整的HRegion信息，这样保证了只需要三次跳转，就能定位到任意 HRegion。\n-ROOT- ：记录 .META. 表的 HRegion 信息。 .META. ：记录用户的表的 HRegion 信息。 客户端查找HRegion信息流程：\n​\tClient==\u0026gt;Zookeeper==\u0026gt; -ROOT- ==\u0026gt;.Meta.==\u0026gt;HRegion\nHBase 0.96 以后 # ​\tHBase 0.96 以后，-ROOT- 表被移除，直接将 .META. 表 HRegion 位置信息存放在 ZooKeeper 中，并将 .META. 表更名为hbase:meta\n客户端查找HRegion信息流程：\n​\tClient==\u0026gt;Zookeepe ==\u0026gt;hbase:meta==\u0026gt;HRegion\nhbase表结构如下:\n读取数据流程 # ","date":"2024-07-26","externalUrl":null,"permalink":"/docs/hbase/","section":"Docs","summary":"HBase # 基本概念 # 什么是HBase # ​\tHBase是一个开源的、高可靠性、高性能、面向列（这里指列族，非列式存储）、可伸缩、实时读写的分布式数据库。","title":"HBase笔记","type":"docs"},{"content":" Hive小问题 # Hive SQL 的执行流程 # 用户首先输入SQL HIve驱动器（Driver）中的解析器将sql解析会抽象语法树，并对抽象语法树进行语义分析 对抽象语法树进行优化 编译器（Compiler）将抽象语法树 （AST） 编译生成逻辑执行计划，接着再将逻辑计划优化并转换为物理计划 执行物理执行计划 返回结果 简化流程图：\nHive 自定义函数的流程，有什么作用 # 编写自定义函数的流程 # 编写Java代码，创建一个java类，这个类需要根据自定义函数的类型（UDF、UDAF、UDTF）来继承相应的类，重写里面的initializ（用于定义输入和输出的参数类型），evaluate（用于实现具体的业务逻辑）等。 打包成jar包 上传到hive集群中 注册函数 使用函数 自定义函数的作用 # 解决特定的业务需求 可以扩展HQL的功能 提高查询效率 提高代码的复用性和模块化 ","date":"2024-07-26","externalUrl":null,"permalink":"/docs/speech-7-26/","section":"Docs","summary":"Hive小问题 # Hive SQL 的执行流程 # 用户首先输入SQL HIve驱动器（Driver）中的解析器将sql解析会抽象语法树，并对抽象语法树进行语义分析 对抽象语法树进行优化 编译器（Compiler）将抽象语法树 （AST） 编译生成逻辑执行计划，接着再将逻辑计划优化并转换为物理计划 执行物理执行计划 返回结果 简化流程图：","title":"speech-7-26","type":"docs"},{"content":" 检查 MySQL 服务是否启动。 [root@node01 ~]# systemctl status mysqld\n启动 ZooKeeper（三台机器都需要执行，使用自己写的脚本） [root@node01 ~]# zookeeper start 或者zookeeper内置命令 zkServer.sh start zkServer.sh status\n启动 HDFS + YARN。 [root@node01 ~]# start-all.sh\n启动 JobHistory. [root@node01 ~]# mapred \u0026ndash;daemon start historyserver\n初始化 hive 数据库（第一次启动时执行）。 [root@node01 ~]# schematool -dbType mysql -initSchema\n启动 MetaStore 服务。\n​ 前台启动，学习期间推荐使用这种方式 [root@node01 ~]# hive \u0026ndash;service metastore\n​ 后台启动 [root@node01 ~]# nohup hive \u0026ndash;service metastore \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\n启动 HiveServer2 服务。 前台启动，学习期间推荐使用这种方式 [root@node01 ~]# hiveserver2 后台启动 [root@node01 ~]# nohup hiveserver2 \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\n客户端连接 # 连接方式一 [root@node03 ~]# hive 退出命令行命令：exit; 客户端连接方式二 [root@node03 ~]# beeline -u jdbc:hive2://node01:10000 -n root 退出命令行命令：!exit 或者 !quit 关闭 # 先关闭 HiveServer2 服务和 MetaStore 服务（前台启动的话直接 Ctrl + C 即可）。\n再关闭 JobHistory 和 Hadoop。 [root@node01 ~]# mapred \u0026ndash;daemon stop historyserver [root@node01 ~]# stop-all.sh\n再关闭 ZooKeeper（三台机器都需要执行，使用自己写的脚本）。\n[root@node01 ~]# zookeeper stop 或者zookeeper内置命令 zkServer.sh stop\n","date":"2024-07-25","externalUrl":null,"permalink":"/docs/hive-start/","section":"Docs","summary":"检查 MySQL 服务是否启动。 [root@node01 ~]# systemctl status mysqld","title":"hive启动步骤","type":"docs"},{"content":"","date":"2024-07-27","externalUrl":null,"permalink":"/docs/","section":"Docs","summary":"","title":"Docs","type":"docs"},{"content":"","date":"2024-07-27","externalUrl":null,"permalink":"/tags/hbase/","section":"Tags","summary":"","title":"Hbase","type":"tags"},{"content":"","date":"2024-07-27","externalUrl":null,"permalink":"/tags/problems/","section":"Tags","summary":"","title":"Problems","type":"tags"},{"content":"","date":"2024-07-27","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2024-07-27","externalUrl":null,"permalink":"/","section":"李","summary":"","title":"李","type":"page"},{"content":"","date":"2024-07-27","externalUrl":null,"permalink":"/tags/%E6%9D%8E/","section":"Tags","summary":"","title":"李","type":"tags"},{"content":"","date":"2024-07-26","externalUrl":null,"permalink":"/tags/hive/","section":"Tags","summary":"","title":"Hive","type":"tags"},{"content":"","date":"2024-07-26","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","date":"2024-07-26","externalUrl":null,"permalink":"/series/%E5%A4%A7%E6%95%B0%E6%8D%AE/","section":"Series","summary":"","title":"大数据","type":"series"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"}]